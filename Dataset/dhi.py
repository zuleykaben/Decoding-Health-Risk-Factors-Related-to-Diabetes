# -*- coding: utf-8 -*-
"""DHI

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1TKAtVht6OQl3kyQ2M3AjjNG98QpYpGea
"""

import pandas as pd
import numpy as np
from sklearn.linear_model import LinearRegression
from matplotlib import pyplot as plt
import seaborn as sns
import statsmodels.api as sm

from google.colab import drive
drive.mount('/content/drive', force_remount=True)

df = pd.read_csv('/content/drive/Shareddrives/Project 2 (Data Science)/Project 2- Team 1/data/diabetes_012_health_indicators_BRFSS2015.csv.zip')

from google.colab import drive
drive.mount('/content/drive')

"""## Cleaning"""

# true/false columns
df['No Diabetes'] = df['Diabetes_012'] == 0 # no diabetes
df['Pre Diabetes'] = df['Diabetes_012'] == 1 # pre diabetes
df['Diabetes'] = df['Diabetes_012'] == 2 # diabetes

df.head(1)

df.columns

df['Diabetes_012'] = df['Diabetes_012'].astype(str)
df['Diabetes_012'] = df['Diabetes_012'].str.replace('0.0','No Diabetes')
df['Diabetes_012'] = df['Diabetes_012'].str.replace('1.0','Pre Diabetes')
df['Diabetes_012'] = df['Diabetes_012'].str.replace('2.0','Diabetes')

df.head(1)

column_counts = df.count()
print(column_counts)
# all columns have the same amount of inputs

"""## Investigating column relationships

Investigating how each column relates to the diabetes outcome.
"""

import matplotlib.pyplot as plt

fig, axs = plt.subplots(nrows=3, ncols=3, figsize=(12, 12))
axs = axs.flatten()

index = 0
for col in df.columns:
    if col not in ['Pre Diabetes', 'Diabetes', 'No Diabetes', 'BMI', 'MentHlth', 'PhysHlth']:
        ax = axs[index]
        df.groupby(col)['Diabetes'].mean().plot(kind='bar', title=col, ax=ax, color = '#3e4a9d')
        ax.axhline(df['Diabetes'].mean(), color='red', linestyle='dashed')
        index += 1

        if index >= len(axs):
            break

plt.tight_layout()
plt.show()

"""## Basic logistic regression model"""

from sklearn.linear_model import LogisticRegression

logr = LogisticRegression(max_iter=10**5)

# random testing
X = df[['HighBP', 'HighChol', 'BMI', 'Smoker', 'Stroke', 'Fruits', 'HvyAlcoholConsump', 'Sex', 'Age', 'Income']]
y = df['Diabetes']

logr.fit(X, y)

preds = logr.predict(X)

df['logr_preds'] = preds

"""Display the results of the fit"""

from sklearn.metrics import ConfusionMatrixDisplay

ConfusionMatrixDisplay.from_predictions(y_true=y, y_pred=preds, normalize='true')

"""Balance diabetes"""

df['Diabetes'].value_counts()

nondiabetic_df = df[df['Diabetes'] == 0]
diabetic_df = df[df['Diabetes'] == 1]

nondiabetic_sample_df = nondiabetic_df.sample(n=len(diabetic_df))

balanced_df = pd.concat([nondiabetic_sample_df, diabetic_df])

balanced_df['Diabetes'].value_counts()

from sklearn.linear_model import LogisticRegression

logr = LogisticRegression(max_iter=10**5)

X = balanced_df[['HighBP', 'HighChol', 'BMI', 'Smoker', 'Stroke', 'Fruits', 'HvyAlcoholConsump', 'Sex', 'Age', 'Income']]
y = balanced_df['Diabetes']

logr.fit(X, y)

preds = logr.predict(X)

balanced_df['logr_preds'] = preds
ConfusionMatrixDisplay.from_predictions(y_true=y, y_pred=preds, normalize='true', cmap='Purples')

# Computing accuracy by hand
np.sum(y == preds) / len(y)

# Computing accuracy using a function
from sklearn.metrics import accuracy_score
accuracy_score(y, preds)

plt.barh(X.columns, logr.coef_[0])

false_positives = (y == False) & (preds == True)
balanced_df['is_false_positive'] = false_positives

balanced_df.head()

# People with high BP are being flagged as diabetic when they are not
balanced_df.groupby('is_false_positive')['HighBP'].mean()

balanced_df.groupby('is_false_positive')['HighChol'].mean()

"""Imagine that these false positives have both high BP and cholesterol, however they tend to have higher income. Then, we'll make a new column for the model to use which flags this."""

balanced_df.head(1)

balanced_df['High readings high earner'] = (balanced_df['HighBP'] == 1) & (balanced_df['HighChol'] == 1) & (balanced_df['Income'] > 6)

balanced_df.head()

# prompt: Find the average of how many people with No diabetes = true and high bp = 1 and high chol = 1 are in the balanced_df

# Calculate the average of people with No diabetes = True, high bp = 1, and high chol = 1
average_people = balanced_df[(balanced_df['No Diabetes'] == True) & (balanced_df['HighBP'] == 1) & (balanced_df['HighChol'] == 1)].shape[0] / balanced_df.shape[0]
print(f"The average of people with No diabetes = True, high bp = 1, and high chol = 1 is: {average_people}")

# prompt: make a dataframe with just the people who don't have diabetes, but have both High bp and high chol

# Create a mask for people without diabetes, with high blood pressure and high cholesterol
no_diabetes_mask = df['Diabetes_012'] == 'No Diabetes'
high_bp_mask = df['HighBP'] == 1.0
high_chol_mask = df['HighChol'] == 1.0

# Apply the masks to filter the DataFrame
filtered_df = df[no_diabetes_mask & high_bp_mask & high_chol_mask]

# Display the resulting DataFrame
filtered_df

filtered_df.head(5)

filtered_df.drop(columns=['Diabetes_012']).groupby('NoDocbcCost').mean()

balanced_df['Good health reading'] = (balanced_df['HeartDiseaseorAttack'] == 0).astype(int) + (balanced_df['DiffWalk'] == 0).astype(int) + (balanced_df['Stroke'] == False).astype(int)

balanced_df['Bad readings, is drinker'] = (balanced_df['HighBP'] == True) & (balanced_df['HighChol'] == True) & (balanced_df['HvyAlcoholConsump'] == True)

balanced_df['Healthcare'] = (balanced_df['AnyHealthcare'] == 1) & (balanced_df['NoDocbcCost'] == 0)

balanced_df['High readings'] = (balanced_df['HighBP'] == 1) & (balanced_df['HighChol']== 1)

balanced_df.head()

#Smoker 'Fruits', 'Veggies',
X = balanced_df[['HighBP', 'HighChol', 'BMI', 'PhysActivity','Stroke',
                 'AnyHealthcare', 'NoDocbcCost', 'GenHlth','MentHlth', 'PhysHlth', 'DiffWalk',
                 'Sex', 'Age', 'Education', 'Income', 'Good health reading', 'Healthcare',
                 'High readings']]
y = balanced_df['Diabetes']

logr.fit(X, y)

preds = logr.predict(X)

balanced_df['logr_preds'] = preds

from sklearn.metrics import ConfusionMatrixDisplay

ConfusionMatrixDisplay.from_predictions(y_true=y, y_pred=preds, normalize='true', cmap = 'Purples')

accuracy_score(y, preds)

plt.barh(X.columns, logr.coef_[0], color = '#df3635')

y.unique()

diabetic_prob_preds = logr.predict_proba(X)[:, 1]

balanced_df['logr_preds_proba'] = diabetic_prob_preds

balanced_df.head()

balanced_df['logr_preds_proba_color'] = None
balanced_df.loc[balanced_df['Diabetes'] == True, 'logr_preds_proba_color'] = 'red'
balanced_df.loc[balanced_df['Diabetes'] == False, 'logr_preds_proba_color'] = 'blue'

plt.hist(balanced_df[balanced_df['Diabetes'] == True]['logr_preds_proba'], color='blue', label='Actual true', alpha=0.5)
plt.hist(balanced_df[balanced_df['Diabetes'] == False]['logr_preds_proba'], color='red', label='Actual false', alpha=0.5)
plt.axvline(0.5, color='red', linestyle='dashed')
plt.legend()

balanced_df['is_false_positive'] = (balanced_df['logr_preds'] != balanced_df['Diabetes']) & (balanced_df['Diabetes'] == False)

balanced_df.head()

# Stack together false positives (no diabetes, but prediction of diabetes) with people with diabetes
diabetic_balanced_df = balanced_df[balanced_df['Diabetes'] == True]
diabetic_balanced_df['diabetic_indic'] = True
false_positives_df = balanced_df[balanced_df['is_false_positive'] == True]
false_positives_df['diabetic_indic'] = False

# Stack both together
diabetic_fp_stacked_df = pd.concat([diabetic_balanced_df, false_positives_df])

import numpy as np

for col in diabetic_fp_stacked_df.select_dtypes(np.number).columns:
  if diabetic_fp_stacked_df[col].nunique() < 10:
    diabetic_fp_stacked_df.groupby('diabetic_indic')[col].mean().plot(kind='barh', title=col)
    plt.show()

plt.hist(balanced_df[balanced_df['Diabetes'] == True]['logr_preds_proba'], color='blue', label='Actual true', alpha=0.5)
plt.hist(balanced_df[balanced_df['Diabetes'] == False]['logr_preds_proba'], color='red', label='Actual false', alpha=0.5)
plt.axvline(0.5, color='red', linestyle='dashed')
plt.legend()

